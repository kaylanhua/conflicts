{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# literature generator\n",
    "generat lit review from a json blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "openai.organization = \"org-raWgaVqCbuR9YlP1CIjclYHk\" # Harvard\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(True if openai.api_key else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of papers:  24\n",
      "dict_keys(['4b6555beef240120bacb699c7d2f7c8e806b5747', 'a4d4053fa12ac75164fe2df0b20a4d3883c292c3', 'da0a744bd257cc50a8778b4452b253bbe3c0b654', '3a8743b858ed557e3c722095ad4d4158e271e0bd', '17c7d2aada72fe59c8d282235b26089d526e44ee', '12e64de7bba4ad1467972309c511d92079477e71', 'b76bdc1d978d921d36069d66b80655ac0aff415b', '0551d31f66171729c1b011584590d411851444b9', '6b393d0fe5210993d17458a082ec9a1bfe040b96', '038c3b0939f17c5f1c6f31ded255f72a014727ed', '97a520228c0d1d5f7410c529a9d924ce187fee77', '23ce1997237735a2acd2bb149bb5ba74c459a70b', 'ad4275b65b5efd84bf44414df9c7325e35fd0e20', '06548af25270dba0a388f081cb2e748c3581d6e1', '3f1ecd5c4c4db5233596e870a2e19b5bc15e435f', '21a102c6051950aa3df388edb6c878dde9ff3a0a', '18c332b0bad296f8722677d2d63092bf02e0c210', 'cf83811d697dc3419a52c9853807afb410eb3943', '8f7892915feb0bd8b16fbe3812b42e6ad6bf05b2', '740d66ba0ab59b1bb38aade6ec7d3170abf1288b', '5f651296106c8860f6a40e831e8f5689f036c56f', '3ac3adc38e2a5fa06e635c4a2a873529ecb981fa', '0e23c5aee6d0c086a2a322fcaec9fad628ae1155', 'fcf53836216c30e43ea8d671f689704679391b78'])\n"
     ]
    }
   ],
   "source": [
    "# prepare information from json blob\n",
    "import json\n",
    "\n",
    "# Read the JSON data from file\n",
    "filename = './rf_jsons/rf24.json'\n",
    "with open(filename, 'r') as file:\n",
    "    papers = json.load(file)\n",
    "\n",
    "print(\"number of papers: \", len(papers))\n",
    "\n",
    "basics = {}\n",
    "\n",
    "for id, paper in papers.items():\n",
    "    paper_info = paper[0]\n",
    "    basics[paper_info['paperId']] = {\n",
    "        'title': paper_info['title'],\n",
    "        'abstract': paper_info['abstract'],\n",
    "        'year': paper_info['year'],\n",
    "        'author': paper_info['authors'][0]['name'] if paper_info['authors'][0] else None\n",
    "    }\n",
    "\n",
    "print(basics.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final string\n",
      "Title: Comparing Random Forest with Logistic Regression for Predicting Class-Imbalanced Civil War Onset Data\n",
      "Abstract: The most commonly used statistical models of civil war onset fail to correctly predict most occurrences of this rare event in out-of-sample data. Statistical methods for the analysis of binary data, such as logistic regression, even in their rare event and regularized forms, perform poorly at prediction. We compare the performance of Random Forests with three versions of logistic regression (classic logistic regression, Firth rare events logistic regression, and L 1-regularized logistic regression), and find that the algorithmic approach provides significantly more accurate predictions of civil war onset in out-of-sample data than any of the logistic regression models. The article discusses these results and the ways in which algorithmic statistical methods like Random Forests can be useful to more accurately predict rare events in conflict data.\n",
      "Author and year: (D. Muchlinski, 2016)\n",
      "\n",
      "Title: edarf: Exploratory Data Analysis using Random Forests\n",
      "Abstract: This package contains functions useful for exploratory data analysis using random forests, which can be fit using the randomForest, randomForestSRC, or party packages (Liaw and Wiener 2002; Ishwaran and Kogalur 2013; Hothorn, Hornik, and Zeileis 2006). These functions can compute the partial dependence of covariates (individually or in combination) on the fitted forests’ predictions, the permutation importance of covariates, as well as the distance between data points according to the fitted model.\n",
      "Author and year: (Z. Jones, 2016)\n",
      "\n",
      "Title: Using Random Forests and Simulated Annealing to Predict Probabilities of Election to the Baseball Hall of Fame\n",
      "Abstract: A popular topic of argument among baseball fans is the prospective Hall of Fame status of current and recently retired players. A player's probability of enshrinement is likely to be affected by a large number of different variables, and can be approached by machine learning methods. In particular, I consider the use of random forests for this purpose. A random forest may be considered a black-box method for predicting the probability of Hall of Fame induction, but a number of parameters must be chosen before the forest can be grown. These parameters include fundamental aspects of the nuts and bolts of the construction of the trees that make up the forest, as well as choices among possible predictor variables. For example, one predictor that may be considered is a measure of the player's having seasons with many home runs hit, and there are multiple competing ways of measuring this. Furthermore, certain deterministic methods of searching the parameter space are partially undermined by the randomness underlying the forest's construction and the fact that, by sheer luck, two forests constructed with the same parameters may have differing qualities of fit. Using simulated annealing, I move through the parameter space in a stochastic fashion, trying many forests and sometimes moving toward a set of parameters even though its fit is apparently not as good as preceding ones. Since probabilities defined based on the votes of terminal nodes of a random forest for classification tend to be too moderate, the results of each forest considered are fed into a logistic regression to produce final probability estimates. From among four simulated annealing runs, the forest with the smallest mean squared error was selected, and analysis of the forests near it in the simulated annealing run indicate that its selection was probably not due to extraordinary \"luck.\" Predictions performed using the out-of-bag samples correctly identify 75% of Baseball Writers Association of America Hall of Fame selections, while misclassifying only 1% of non-selections. Results indicate a smaller mean squared error than a previous neural network approach, although the large number of forests tried and discarded raised concerns about overfitting in this case.\n",
      "Author and year: (M. Freiman, 2010)\n",
      "\n",
      "Title: Navigating Random Forests and related advances in algorithmic modeling\n",
      "Abstract: : This article addresses current methodological research on non-parametric Random Forests. It provides a brief intellectual history of Random Forests that covers CART, boosting and bagging methods. It then introduces the primary methods by which researchers can visualize results, the relationships between covariates and responses, and the out-of-bag test set error. In addition, the article considers current research on universal consistency and importance tests in Random Forests. Finally, several uses for Random Forests are discussed, and available software is identiﬁed.\n",
      "Author and year: (David S. Siroky, 2009)\n",
      "\n",
      "Title: Conflict Prediction via Machine Learning: Addressing the Rare Events Problem with Bagging\n",
      "Abstract: Machine learning deals with the development of algorithms for classification and prediction. However, these algorithms have only in rare cases been used in political science. This poster demonstrates the application of state-of-the-art machine learning techniques to the prediction of conflict. In order to address the rare events problem, I use an ensemble of classifiers built on subsets of the training data. These subsets include all positive cases, and a random selection of negative ones. Although I focus primarily on decision tree learning, the proposed method can be used in conjunction with different classification algorithms in order to improve the prediction of conflict onset.\n",
      "Author and year: (Nils B. Weidmann, 2008)\n",
      "\n",
      "Title: Predicting (de-)escalation of sub-national violence using gradient boosting: Does it work?\n",
      "Abstract: Abstract This article presents a prediction model of (de-)escalation of sub-national violence using gradient boosting. The prediction model builds on updated data from the PRIO-GRID data aggregator, contributing to the ViEWS prediction competition by predicting changes in violence levels, operationalized using monthly fatalities at the 0.5 × 0.5-degree grid (pgm) level. Our model's predictive performance in terms of mean square error (MSE) is marginally worse than the ViEWS baseline model and inferior to most other submissions, including our own supervised random forest model. However, while we knew that the model was comparatively worse than our random forest model in terms of MSE, we propose the gradient boosting model because it performed better where it matters—in predicting when (de-)escalation happens. This choice means that we question the usefulness of using MSE for evaluating model performance and instead propose alternative performance measurements that are needed to understand the usefulness of predictive models. We argue that future endeavors using this outcome should measure their performance using the Concordance Correlation, which takes both the trueness and the precision elements of accuracy into account, and, unlike MSE, seems to be robust to the issues caused by zero inflation. Este artículo presenta un modelo de predicción de la desescalada de la violencia subnacional mediante el uso de la potenciación del gradiente. El modelo de predicción se basa en los datos actualizados que provienen del agregador de datos de PRIO-GRID, contribuye al concurso de predicciones de ViEWS al predecir cambios en los niveles de violencia y es operacionalizado utilizando las muertes mensuales a nivel de cuadrícula de 0.5 × 0.5 grados (pgm). El rendimiento predictivo de nuestro modelo desde el punto de vista del error cuadrático medio (mean square error, MSE) es ligeramente peor que el modelo de referencia del sistema de alerta temprana sobre la violencia (Violence Early Warning System, ViEWS) e inferior en relación con la mayoría de las otras presentaciones, incluido nuestro modelo de bosque aleatorio y supervisado. No obstante, si bien sabíamos que el modelo era comparativamente peor que nuestro modelo de bosque aleatorio en relación con el MSE, proponemos el modelo de potenciación del gradiente porque funcionó mejor en el aspecto que importa: predecir cuándo ocurre la desescalada. Esta elección significa que cuestionamos la utilidad del uso del MSE para evaluar el rendimiento del modelo y, en cambio, proponemos mediciones de rendimiento alternativas que son necesarias para comprender la utilidad de los modelos predictivos. Sostenemos que, en los futuros proyectos en los que se utilice este resultado, se debería medir el rendimiento mediante la correlación de concordancia, la cual tiene en cuenta tanto los elementos de veracidad como los de precisión de la exactitud y, a diferencia del MSE, parece ser resistente a los problemas generados por la inflación cero. Cet article présente un modèle de prédiction de la (dés)escalade de la violence infranationale utilisant un boosting de gradient. Ce modèle de prédiction repose sur des données à jour de l’agrégateur de données de la grille PRIO. Il contribue au concours de prédiction ViEWS (Violence early-warning system, système d’alerte précoce sur la violence) en prédisant les évolutions des niveaux de violence qui sont opérationnalisés sur la base du nombre mensuel de décès au niveau 0.5 × 0.5 degré de la grille (PGM). Les performances prédictives de notre modèle en termes d’erreur quadratique moyenne (EQM) sont légèrement moins bonnes que celles du modèle de référence ViEWS et inférieures à la plupart des autres modèles soumis, y compris à celles de notre propre modèle à forêt aléatoire supervisée. Cependant, bien que nous sachions que ce modèle à boosting de gradient était comparativement moins bon que notre modèle à forêt aléatoire en termes d’EQM, nous l’avons proposé car il était plus efficace dans le domaine qui compte : la prédiction du moment auquel une (dés)escalade interviendrait. Ce choix signifie que nous remettons en question l’utilité de l’utilisation de l’EQM pour évaluer les performances des modèles et nous proposons au lieu de cela des mesures de performances alternatives nécessaires pour comprendre l’utilité des modèles prédictifs. Nous soutenons que les futurs efforts utilisant ce résultat devraient plutôt mesurer leurs performances à l’aide de la Corrélation de concordance, qui prend à la fois en compte les éléments Exactitude et Précision et qui, contrairement à l’EQM, semble être robuste face aux problèmes causés par l’inflation zéro.\n",
      "Author and year: (Jonas Vestby, 2022)\n",
      "\n",
      "Title: Forecasting conflict using a diverse machine-learning ensemble: Ensemble averaging with multiple tree-based algorithms and variance promoting data configurations\n",
      "Abstract: Abstract The article examines the potential of multi-model ensemble learning techniques for conflict research and applies an ensemble averaging framework to the prediction task of the 2020 ViEWS armed conflict forecasting competition. The goal is to predict changes of conflict intensity in fifty-four African countries for 6 months into the future. The presented ensemble combines six individual models, using two tree-based learning algorithms, incorporating two distinct data foundations and two geographical selections into a unified forecasting framework. In one of the two applied datasets, the combination of conflict variables from recent months is implemented to train for inter-temporal connections of previous conflict levels. The second dataset contains important structural, economic, political, and social information relevant for each individual case. Both datasets are used to predict changes in conflict levels. The framework structure and the combination method are presented in detail, and the prediction results for both test periods between 2014–2016 and 2016–2019 are evaluated regarding their quality. The effect of the ensemble structure and the performance of all individual components is comprehensively examined. Real forecasts over the timespan of six months into the future are presented for the upcoming months of October 2020 through March 2021 generated from data available until August 2020. The paper concludes with the presentation and examination of three selected case forecasts for Egypt, Cameroon, and Mozambique. El artículo examina el potencial de las técnicas de aprendizaje de conjuntos multimodelos para la investigación de conflictos y aplica un marco de promedio de conjuntos a la tarea de predicción del concurso de previsión de conflictos armados; ViEWS 2020. La meta es predecir los cambios en la intensidad de los conflictos en cincuenta y cuatro países africanos durante seis meses en el futuro. El conjunto presentado combina seis modelos individuales, que utilizan dos algoritmos de aprendizaje basados en árboles, y que incorporan dos bases de datos distintas y dos selecciones geográficas en un marco de previsión unificado. En uno de los dos conjuntos de datos aplicados, se implementa la combinación de variables de conflicto de los últimos meses para estudiar las conexiones intertemporales de los niveles de conflicto anteriores. El segundo conjunto de datos contiene información estructural, económica, política y social importante para cada caso individual. Ambos conjuntos de datos se utilizan para predecir los cambios en los niveles de conflicto. La estructura del marco y el método de combinación se presentan en detalle, y se evalúa la calidad de los resultados de la predicción para ambos períodos de prueba entre 2014-2016 y 2016-2019. Se analiza a fondo el efecto de la estructura del conjunto y el funcionamiento de todos los componentes individuales. Se presentan previsiones reales a seis meses, para los próximos meses de octubre de 2020 a marzo de 2021, generados a partir de los datos disponibles hasta agosto de 2020. El artículo concluye con la presentación y el análisis de tres previsiones de casos seleccionados de Egipto, Camerún y Mozambique. Cet article examine le potentiel des techniques d’apprentissage ensembliste multi-modèles pour les recherches sur les conflits et applique un cadre de moyennage ensembliste à la tâche de prédiction du concours de prévision des conflits armés ViEWS (violence early-warning system, système d’alerte précoce sur la violence) 2020. L’objectif est de prédire les changements d’intensité des conflits dans cinquante-quatre pays africains sur les six mois à venir. L’ensemble présenté combine six modèles individuels en utilisant deux algorithmes d’apprentissage basés sur des arbres et en intégrant deux fondations de données distinctes et deux sélections géographiques à une infrastructure de prévision unifiée. Dans l’un des deux jeux de données appliqués, la combinaison des variables de conflit des derniers mois est implémentée pour entraîner les algorithmes sur les relations inter-temporelles des intensités de conflits précédentes. Le deuxième jeu de données contient d’importantes informations structurelles, économiques, politiques et sociales concernant chacun des cas individuels. Les deux jeux de données sont utilisés pour prédire les changements d’intensité des conflits. La structure de l’infrastructure et la méthode de combinaison sont présentées en détails et la qualité des résultats des prédictions est évaluée pour les deux périodes de test, 2014-2016 et 2016-2019. L’effet de la structure ensembliste et les performances de toutes les composantes individuelles sont examinés en profondeur. Les prévisions réelles sur une période de six mois sont présentées pour les mois à venir qui étaient octobre 2020 à mars 2021. Ces prévisions avaient été générées à partir des données disponibles jusqu’août 2020. L’article conclut par une présentation et un examen d’une sélection de prévisions pour trois cas, ceux de l’Égypte, du Cameroun et du Mozambique. Video Abstract Read the transcript Watch the video on Vimeo\n",
      "Author and year: (Felix Ettensperger, 2021)\n",
      "\n",
      "Title: Efficient and robust high-dimensional sparse logistic regression via nonlinear primal-dual hybrid gradient algorithms\n",
      "Abstract: Logistic regression is a widely used statistical model to describe the relationship between a binary response variable and predictor variables in data sets. It is often used in machine learning to identify important predictor variables. This task, variable selection, typically amounts to fitting a logistic regression model regularized by a convex combination of l1 and l 2 2 penalties. Since modern big data sets can contain hundreds of thousands to billions of predictor variables, variable selection methods depend on efficient and robust optimization algorithms to perform well. State-of-the-art algorithms for variable selection, however, were not traditionally designed to handle big data sets; they either scale poorly in size or are prone to produce unreliable numerical results. It therefore remains challenging to perform variable selection on big data sets without access to adequate and costly computational resources. In this paper, we propose a nonlinear primal-dual algorithm that addresses these shortcomings. Specifically, we propose an iterative algorithm that provably computes a solution to a logistic regression problem regularized by an elastic net penalty inO(T (m,n) log(1/ǫ)) operations, where ǫ ∈ (0, 1) denotes the tolerance and T (m,n) denotes the number of arithmetic operations required to perform matrix-vector multiplication on a data set with m samples each comprising n features. This result improves on the known complexity bound of O(min(mn,mn) log(1/ǫ)) for first-order optimization methods such as the classic primal-dual hybrid gradient or forward-backward splitting methods. Significance statement Logistic regression is a widely used statistical model to describe the relationship between a binary response variable and predictor variables in data sets. With the trends in big data, logistic regression is now commonly applied to data sets whose predictor variables range from hundreds of thousands to billions. State-of-the-art algorithms for fitting logistic regression models, however, were not traditionally designed to handle big data sets; they either scale poorly in size or are prone to produce unreliable numerical results. This paper proposes a nonlinear primal-dual algorithm that provably computes a solution to a logistic regression problem regularized by an elastic net penalty in O(T (m,n) log(1/ǫ)) operations, where ǫ ∈ (0, 1) denotes the tolerance and T (m,n) denotes the number of arithmetic operations required to perform matrix-vector multiplication on a data set with m samples each comprising n features. This result improves on the known complexity bound of O(min(m2n,mn2) log(1/ǫ)) for first-order optimization methods such as the classic primal-dual hybrid gradient or forward-backward splitting methods.\n",
      "Author and year: (J. Darbon, 2021)\n",
      "\n",
      "Title: Machine Learning Prediction Models for Mortality in Intensive Care Unit Patients with Lactic Acidosis\n",
      "Abstract: Background: Lactic acidosis is the most common cause of anion gap metabolic acidosis in the intensive care unit (ICU), associated with poor outcomes including mortality. We sought to compare machine learning (ML) approaches versus logistic regression analysis for prediction of mortality in lactic acidosis patients admitted to the ICU. Methods: We used the Medical Information Mart for Intensive Care (MIMIC-III) database to identify ICU adult patients with lactic acidosis (serum lactate ≥4 mmol/L). The outcome of interest was hospital mortality. We developed prediction models using four ML approaches consisting of random forest (RF), decision tree (DT), extreme gradient boosting (XGBoost), artificial neural network (ANN), and statistical modeling with forward stepwise logistic regression using the testing dataset. We then assessed model performance using area under the receiver operating characteristic curve (AUROC), accuracy, precision, error rate, Matthews correlation coefficient (MCC), F1 score, and assessed model calibration using the Brier score, in the independent testing dataset. Results: Of 1919 lactic acidosis ICU patients, 1535 and 384 were included in the training and testing dataset, respectively. Hospital mortality was 30%. RF had the highest AUROC at 0.83, followed by logistic regression 0.81, XGBoost 0.81, ANN 0.79, and DT 0.71. In addition, RF also had the highest accuracy (0.79), MCC (0.45), F1 score (0.56), and lowest error rate (21.4%). The RF model was the most well-calibrated. The Brier score for RF, DT, XGBoost, ANN, and multivariable logistic regression was 0.15, 0.19, 0.18, 0.19, and 0.16, respectively. The RF model outperformed multivariable logistic regression model, SOFA score (AUROC 0.74), SAP II score (AUROC 0.77), and Charlson score (AUROC 0.69). Conclusion: The ML prediction model using RF algorithm provided the highest predictive performance for hospital mortality among ICU patient with lactic acidosis.\n",
      "Author and year: (P. Pattharanitima, 2021)\n",
      "\n",
      "Title: Prevention Is Better Than Cure: Machine Learning Approach to Conflict Prediction in Sub-Saharan Africa\n",
      "Abstract: This article offers policymakers and researchers pragmatic and sustainable approaches to identify and mitigate conflict threats by looking beyond p-values and plausible instruments. We argue that predicting conflict successfully depends on the choice of algorithms, which, if chosen accurately, can reduce economic and social instabilities caused by post-conflict reconstruction. After collating data with variables linked to conflict, we used a grid level dataset of 5928 observations spanning 48 countries across sub-Saharan Africa to predict civil conflict. The goals of the study were to assess the performance of supervised classification machine learning (ML) algorithms in comparison with logistic model, assess the implication of selecting a specific performance metric on policy initiatives, and evaluate the value of interpretability of the selected model. After comparing class imbalance resampling methods, the synthetic minority over-sampling technique (SMOTE) was employed to improve out-of-sample prediction for the trained model. The results indicate that if our selected performance metric is recall, gradient tree boosting is the best algorithm; however, if precision or F1 score is the selected metric, then the multilayer perceptron algorithm produces the best model.\n",
      "Author and year: (Mark Musumba, 2021)\n",
      "\n",
      "Title: Development and Technical Validation of a Smartphone-Based Cry Detection Algorithm\n",
      "Abstract: Introduction: The duration and frequency of crying of an infant can be indicative of its health. Manual tracking and labeling of crying is laborious, subjective, and sometimes inaccurate. The aim of this study was to develop and technically validate a smartphone-based algorithm able to automatically detect crying. Methods: For the development of the algorithm a training dataset containing 897 5-s clips of crying infants and 1,263 clips of non-crying infants and common domestic sounds was assembled from various online sources. OpenSMILE software was used to extract 1,591 audio features per audio clip. A random forest classifying algorithm was fitted to identify crying from non-crying in each audio clip. For the validation of the algorithm, an independent dataset consisting of real-life recordings of 15 infants was used. A 29-min audio clip was analyzed repeatedly and under differing circumstances to determine the intra- and inter- device repeatability and robustness of the algorithm. Results: The algorithm obtained an accuracy of 94% in the training dataset and 99% in the validation dataset. The sensitivity in the validation dataset was 83%, with a specificity of 99% and a positive- and negative predictive value of 75 and 100%, respectively. Reliability of the algorithm appeared to be robust within- and across devices, and the performance was robust to distance from the sound source and barriers between the sound source and the microphone. Conclusion: The algorithm was accurate in detecting cry duration and was robust to various changes in ambient settings.\n",
      "Author and year: (A. Zhuparris, 2021)\n",
      "\n",
      "Title: Revisiting the Contested Role of Natural Resources in Violent Conflict Risk through Machine Learning\n",
      "Abstract: The integrated character of the sustainable development goals in Agenda 2030, as well as research in environmental security, flag that sustainable peace requires sustainable and conflict-sensitive natural resource use. The precise relationship between the risk for violent conflict and natural resources remains contested because of the interplay with socio-economic variables. This paper aims to improve the understanding of natural resources’ role in the risk of violent conflicts by accounting for complex interactions with socio-economic conditions. Conflict data was analysed with machine learning techniques, which can account for complex patterns, such as variable interactions. More commonly used logistic regression models are compared with neural network models and random forest models. The results indicate that a country’s natural resource features are important predictors of its risk for violent conflict and that they interact with socio-economic conditions. Based on these empirical results and the existing literature, we interpret that natural resources can be root causes of violent intrastate conflict, and that signals from natural resources leading to conflict risk are reflected in and influenced by interacting socio-economic conditions. More specifically, the results show that variables such as access to water and food security are important predictors of conflict, while resource rents and oil and ore exports are relatively less important than other natural resource variables, contrasting what prior research has suggested. Given the potential of natural resource features to act as an early warning for violent conflict, we argue that natural resources should be included in conflict risk models for conflict prevention.\n",
      "Author and year: (Marie K. Schellens, 2020)\n",
      "\n",
      "Title: Predicting the costs of war\n",
      "Abstract: The expected cost of war is a foundational concept in the study of international conflict. However, the field currently lacks a measure of the expected costs of war, and thereby any measure of the bargaining range. In this paper, I develop a proxy for the expected costs of war by focusing on one aspect of war costs – battle deaths. I train a variety of machine learning algorithms on battle deaths for all countries participating in fatal military disputes and interstate wars between 1816 and 2007 in order to maximize out-of-sample predictive performance. The best performing model (random forest) improves performance over that of a null model by 25% and a linear model with all predictors by 9%. I apply the random forest to all interstate dyads in the Correlates of War dataverse from 1816 to 2007 in order to produce an estimate of the expected costs of war for all existing country pairs in the international system. The resulting measure, which I refer to as Dispute Casualty Expectations, can be used to fully explore the implications of the bargaining model of war, as well as allow applied researchers to develop and test new theories in the study of international relations.\n",
      "Author and year: (Phil Henrickson, 2020)\n",
      "\n",
      "Title: Predictive inference with random forests: A new perspective on classical analyses\n",
      "Abstract: Despite the number of problems that can occur when core model assumptions are violated, nearly all quantitative political science research relies on inflexible regression models that require a linear relationship between dependent and independent variables for valid inference. We argue that nonparametric statistical learning methods like random forests are capable of combining the benefits of interpretability and flexibility. Recent work has shown that under suitable regularity conditions, averaging over predictions made by subsampled random forests produces asymptotically normal predictions. After estimating the variance, this property can be exploited to produce hypothesis tests and confidence intervals analogous to those produced within a parametric framework. We demonstrated the utility of this approach by replicating an important study on the determinants of civil war onset and show that subtle nonlinear relationships are uncovered, providing a new perspective on these ongoing research questions.\n",
      "Author and year: (Richard J. McAlexander, 2020)\n",
      "\n",
      "Title: International politics by other means: External sources of civil war\n",
      "Abstract: The literature on civil wars has recently turned towards their international context but lacks an account for how conflict beyond a state’s borders contributes to civil war onset. I argue that interstate rivalries can increase the risk of civil war in other states when rivals come to associate the foreign-policy orientation of other states with their own security. I present three pathways through which rivals increase the risk of civil war in other states. First, competition between rivals creates a ratchet effect by which the prospect of one’s involvement in a conflict makes it more likely that the other becomes involved. This dynamic makes support easier to secure and lowers the expected costs of war for governments and opposition groups. Second, rivals encourage domestic polarization as parties attempt to capture their influence, making domestic conflicts more intractable. Third, uncertainty over the potential for intervention by rivals increases the risk of miscalculation. I test the implications of the theory with novel spatial measures of interstate conflict and rivalry. Using logistic regressions and random forests, I find that being in the neighborhood of interstate rivals can increase a state’s risk of civil war.\n",
      "Author and year: (Mark Toukan, 2019)\n",
      "\n",
      "Title: Improving Supreme Court Forecasting Using Boosted Decision Trees\n",
      "Abstract: Though used frequently in machine learning, boosted decision trees are largely unused in political science, despite many useful properties. We explain how to use one variant of boosted decision trees, AdaBoosted decision trees (ADTs), for social science predictions. We illustrate their use by examining a well-known political prediction problem, predicting U.S. Supreme Court rulings. We find that our ADT approach outperforms existing predictive models. We also provide two additional examples of the approach, one predicting the onset of civil wars and the other predicting county-level vote shares in U.S. presidential elections.\n",
      "Author and year: (A. Kaufman, 2019)\n",
      "\n",
      "Title: Is There More Violence in the Middle?\n",
      "Abstract: Is there more violence in the middle? Over 100 studies have analyzed whether violent outcomes such as civil war, terrorism, and repression are more common in regimes that are neither full autocracies nor full democracies, yet findings are inconclusive. While this hypothesis is ultimately about functional form, existing work uses models in which a particular functional form is assumed. Existing work also uses arbitrary operationalizations of “the middle.” This article aims to resolve the empirical uncertainty about this relationship by using a research design that overcomes the limitations of existing work. We use a random forest-like ensemble of multivariate regression and classification trees to predict multiple forms of conflict. Our results indicate the specific conditions under which there is or is not more violence in the middle. We find the most consistent support for the hypothesis with respect to minor civil conflict and no support with respect to repression. Replication Materials: The data, code, and any additional materials required to replicate all analyses in this article are available on the American Journal of Political Science Dataverse within the Harvard Dataverse Network, at: https://doi.org/10.7910/DVN/LNUYXZ. What is the relationship between regime type and political violence? Are certain forms of conflict more likely in democracies or in autocracies? A series of influential studies has suggested this relationship is curvilinear, with violence most likely in regimes in the middle range—often referred to as anocracies—that are neither fully autocratic nor fully democratic (Eck and Hultman 2007; Fein 1995; Hegre et al. 2001). We refer to these arguments, collectively, as the More Violence in the Middle Hypothesis (or MVM Hypothesis). Despite decades of research, the extent to which such theories are empirically supported is unclear. While some early studies found that civil wars are most likely in anocracies (Hegre et al. 2001), others did not (Sambanis 2001). The debate may have appeared resolved when Vreeland (2008) showed that correcting for the extent to which measures of democracy might include indicators of violence results in no support for the MVM Hypothesis, but since then some have used his measure and found support for the hypothesis (Gleditsch and Ruggeri 2010), whereas others have confirmed his result (Peic and Reiter 2011). Likewise, some find evidence that terrorism is most Zachary M. Jones is Postdoctoral Fellow, eScience Institute, Campus Box 351570, University of Washington, Seattle, WA 98195-1570 (zmj@zmjones.com). Yonatan Lupu is Assistant Professor, Department of Political Science, George Washington University, Monroe Hall, Room 417, 2115 G Street, NW, Washington, DC 20052 (ylupu@gwu.edu). For comments on previous drafts, we thank Erica Chenoweth, Christian Davenport, Scott Gates, Will Moore, and Jake Shapiro, as well as participants in workshops at New York University, Uppsala University, and George Washington University. For research assistance, we thank Jack Hasler, Bryce Loidolt, and Steven Schaaf. common in anocracies (Wade and Reiter 2007), whereas others do not (Chenoweth 2010). With respect to repression, Davenport and Armstrong (2004) arguably settled the question by using more appropriate methods for testing this hypothesis than the bulk of the literature and finding no support for the MVM Hypothesis, but some recent work continues to find support for it (Mitchell, Ring, and Spellman 2013). The purpose of this article is to reduce the empirical uncertainty about the MVM Hypothesis and describe the conditions under which it does or does not hold. Although existing work has made significant progress, the methods used to date have several consequential limitations. The MVM Hypothesis is a prediction about the functional form of the relationship between regime type and conflict, yet almost all existing tests of the MVM Hypothesis have been conducted using models that assume a particular functional form and then test whether the data allow us to reject a simpler possible relationship between regime type and conflict, such as a monotonic relationship. While such tools can allow us to reject a monotonic relationship, they are not well suited for understanding the more complex ways in which regime type American Journal of Political Science, Vol. 62, No. 3, July 2018, Pp. 652–667 C ©2018, Midwest Political Science Association DOI: 10.1111/ajps.12373\n",
      "Author and year: (Z. Jones, 2018)\n",
      "\n",
      "Title: Tree-Based Models for Political Science Data\n",
      "Abstract: Political scientists often find themselves analyzing data sets with a large number of observations, a large number of variables, or both. Yet, traditional statistical techniques fail to take full advantage of the opportunities inherent in “big data,” as they are too rigid to recover nonlinearities and do not facilitate the easy exploration of interactions in high-dimensional data sets. In this article, we introduce a family of tree-based nonparametric techniques that may, in some circumstances, be more appropriate than traditional methods for confronting these data challenges. In particular, tree models are very effective for detecting nonlinearities and interactions, even in data sets with many (potentially irrelevant) covariates. We introduce the basic logic of tree-based models, provide an overview of the most prominent methods in the literature, and conduct three analyses that illustrate how the methods can be implemented while highlighting both their advantages and limitations. Replication Materials: The data, code, and any additional materials required to replicate all analyses in this article are available on the American Journal of Political Science Dataverse within the Harvard Dataverse Network at: https://doi.org/10.7910/DVN/8ZJBLI. Social science scholars often work with data sets containing a large number of observations, many potential covariates, or (increasingly) both. Indeed, political scientists now regularly analyze data with levels of complexity unimaginable just two decades ago. Widely used surveys, for instance, interview tens of thousands of respondents about hundreds of topics. Scholars of institutions can quickly assemble data sets with thousands of observations using resources like the Comparative Agendas Project. Moreover, new measurement methods, such as text analysis, have combined with data sources, such as Twitter, to generate databases of almost unmanageable sizes. It is clear that political science, like all areas of the social sciences, will increasingly have access to a deluge of data so vast that it will dwarf everything that has come before. What statistical methods are needed in this datasaturated world? Surely, there is no one correct answer. Yet, just as surely, traditional statistical models are not always equipped to take full advantage of new data sources. Traditional models—largely variants of linear regressions—are ideal for evaluating theories that imply specific functional forms relating outcomes to predictors. In particular, they excel in their ability to leverage assumptions about the data-generating process, or DGP (additivity, linearity in the parameters, homoskedasticity, Jacob M. Montgomery is Associate Professor, Department of Political Science, Washington University in St. Louis, Campus Box 1063, One Brookings Drive, St. Louis, MO 63130 (jacob.montgomery@wustl.edu). Santiago Olivella is Assistant Professor, Department of Political Science, University of North Carolina at Chapel Hill, Hamilton Hall 361, CB 3265, Chapel Hill, NC 27599 (olivella@unc.edu). etc.) to make valid inferences despite inherent data limitations. Although appropriate when testing theories that conform with these assumptions, standard models are often insufficiently flexible to capture nuances in the data—such as complex nonlinear functional forms and deep interactions—when no clear a priori expectations exist. In this article, we introduce a family of tree-based nonparametric techniques from the machine learning literature. We argue that, under specific circumstances, regression and classification tree models are an appropriate standard choice for analyzing high-dimensional data sets. In particular, past research has shown tree-based methods to be very useful for making accurate predictions when the underlying DGP includes nonlinearities, discontinuities, and interactions among many covariates. Further, tree models require few assumptions. Rather than imposing a presumed structure on the DGP, tree-based methods allow the data to “speak for themselves.” Thus, our goal in this article is to introduce political scientists to this promising family of methods, which are well suited for today’s data analysis demands. In the next sections, we discuss the promise and perils of high-dimensional, “large”-N data sets and introduce the basic logic of tree models. We then provide an overview of the most prominent methods in the literature. American Journal of Political Science, Vol. 62, No. 3, July 2018, Pp. 729–744 C ©2018, Midwest Political Science Association DOI: 10.1111/ajps.12361\n",
      "Author and year: (J. Montgomery, 2018)\n",
      "\n",
      "Title: Random or Retributive?: Indiscriminate Violence in the Chechen Wars\n",
      "Abstract: This article provides a critical examination of the current theoretical debate concerning the effects of indiscriminate violence. It argues that indiscriminate violence has been treated as an essentially random counterinsurgency tactic, but that the important distinction between its random and retributive variations has been overlooked, along with critical issues of timing and location, which has made it difficult to evaluate its efficacy in quelling rebel violence. Prior research has shown that both random and retributive violence reduced insurgent activity in the targeted locations and in the short term, but it does not necessarily follow that indiscriminate violence is effective. This article uses microlevel ethnographic evidence from Chechen villages during the period from 2001 to 2005 to show that indiscriminate violence deployed retributively against village communities generated insurgent activity in other areas because local avengers and rebels from the targeted populations sought to avoid further retributive violence against their village communities. Moreover, the insurgent activity occurred at least nine months after the initial act of retributive violence. Indiscriminate violence deployed randomly against village communities generated insurgent activity within the same targeted area, since the insurgents did not fear retributive violence in retaliation, and occurred with a delay of at least six months. As a result, the rebel reaction to indiscriminate violence is not observed immediately or, in the case of retributive violence, in the same location. This finding has crucial implications for evaluating the efficacy of indiscriminate violence in counterinsurgency operations, and underscores the importance of understanding how the social and political context can shape the way populations react to different forms of violence.\n",
      "Author and year: (E. Souleimanov, 2016)\n",
      "\n",
      "Title: Modeling Complex DDA Purchasing and Use Patterns with\n",
      "Abstract: This paper describes a project aimed at exploring the practical application of machine learning in the library environment by way of demand-driven acquisitions (DDA). This research uses DDA program purchasing data to build predictive models of future DDA purchasing by two separate methods. A model utilizing the Adaptive Boosting (AdaBoost) algorithm is compared against a model utilizing a more traditional logistic regression method, to determine what benefits, if any, machine learning offers toward predicting DDA purchasing patterns. This paper also explores, if only superficially, additional questions surrounding applied machine learning in the academic library setting and its meaning in relation to established library assessment practice.\n",
      "Author and year: (Kevin W. Walker, 2021)\n",
      "\n",
      "Title: Decision Tree Guided Multi-Class Support Vector Machines with Dynamic Class Selections\n",
      "Abstract: Large-scale terrorism datasets are inherently different from other political science datasets in that they are mostly incomplete owing to the clandestine nature of the very phenomenon they seek to capture. This problem is compounded by two important factors: event-based terrorism databases generally rely on news reports that rarely provide full facts about these incidents, and perpetrators of these acts usually prefer not to disclose their identity or supply reliable data on their activities. The unclaimed terrorist attacks thus pose some challenging inference problems for researchers interested in using such datasets to test hypotheses related to terrorist groups. In this paper, I attempt to solve this problem of missing data for the most comprehensive event-based terrorism dataset Global Terrorism Dataset (GTD) , by using machine learning algorithms. I first use Multivariate Imputation by Chained Equations (MICE) to impute missing event characteristics (such as types of attack, weapon, and target, numbers of killed and wounded, and etc.), and then use these complete attributes as predictors in a novel Decision-Tree guided Multi-class Support Vector Machine algorithm to attribute unclaimed terror attacks to known terror groups. I classify all of the events that are listed as having unknown perpetrators, which accounts for half of the entire dataset, by comparing their properties with information obtained from events whose perpetrators are known.\n",
      "Author and year: (Roya Talibova, 2021)\n",
      "\n",
      "Title: Predicting the severity of civil wars: An actor-centric approach\n",
      "Abstract: We introduce an actor-centric approach to predict the severity of conflict one and six months into the future. We argue that the prediction of conflict severity needs to focus on the actors that are responsible for conducting armed violence. Hence, we predict the severity of conflict in government-rebel organization dyads. Our predictors focus especially on rebel organization characteristics, behavior, and the conflict networks actors are embedded in. Our statistical learning approach relies on random forests to predict the severity of conflict. We demonstrate that our model performs especially well distinguishing high levels of severity from very low levels.\n",
      "Author and year: (Nils W. Metternich, 2019)\n",
      "\n",
      "Title: DOES a state ’ s use of indiscriminate violence incite insurgent attacks ? The conventional wisdom suggests that it does —\n",
      "Abstract: D a state’s use of indiscriminate violence incite insurgent attacks? The conventional wisdom suggests that it does—Stathis Kalyvas1 cites dozens of studies and historical cases where collective targeting of the noncombatant population provoked greater insurgent violence. But others have pushed back against this claim.2 These scholars have made significant advances that allow us to understand and explain when, why, and how the world’s militaries have used indiscriminate violence against noncombatants with shocking regularity. This study builds on these contributions. We use interviews we conducted with ex-combatants and eyewitnesses of the Chechen wars to provide a critical reexamination of the current theoretical debate concerning indiscriminate violence. In doing so, we argue that treating the concept of indiscriminate violence as an essentially random counterinsurgency tactic obscures the important distinction between random and retributive indiscriminate violence deployed against civilians. The distinction raises crucial questions of location and timing that have hindered efforts to evaluate the efficacy of indiscriminate violence in irregular war. Even if indiscriminate violence does lead to a short-term decrease in insurgent activity in the targeted locations as prior research has shown, it does not follow that indiscriminate violence is necessarily effective, for two reasons. After a period of recovery, many local insurgents and prospective avengers from the targeted villages in Chechnya retaliated. But it took prospective Chechen avengers at least six to nine months to\n",
      "Author and year: (David S. Siroky, 2016)\n",
      "\n",
      "Title: Boosted Decision Tree (BDT) model for political analysis: Using machine learning to assess the Anonymous campaign against Islamic Extremists on Twitter\n",
      "Abstract: Social scientists now have unprecedented access to a wealth of information on human behavior, but \"big data\" pose unique analytical challenges. Classic regression models, which make rigid assumptions regarding the data generating process, are often unsuited for extracting information from big data. Machine learning (ML) models, in contrast, are ideal for this task because they are flexible. In this article, we review major families of ML models, with a focus on Boosted Decision Tree (BDT) models, which is the gold standard of ML models. Furthermore, we explain how to compute the \"marginal effect\" of any variable and uncertainty estimates for ML models. We illustrate our techniques with an analysis of an original dataset of 16,286 suspicious jihadist Twitter accounts reported by cyber activists. This article provides a guide on ML methods for political scientists, and contributes to our understanding of the politics of social media. ∗Corresponding author. ABD, Department of Political Science, and Master’s Candidate in Statistics, Department of Mathematics, Washington University at St. Louis. elena.labzina@wustl.edu. †Dickey Fellow in U.S.Foreign Policy and International Security, Dartmouth College. george.yin1@gmail.com.\n",
      "Author and year: (Elena Labzina, None)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paper_abstracts = \"\"\n",
    "\n",
    "for id, entry in basics.items():\n",
    "    paper_abstracts += \"Title: \" + entry[\"title\"] + '\\n' + \"Abstract: \" + entry[\"abstract\"] + '\\n' + \"Author and year: (\" + entry[\"author\"] + ', ' + str(entry[\"year\"]) + ')\\n\\n'\n",
    "\n",
    "print(\"final string\")\n",
    "print(paper_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "with open('res.txt', 'w') as txtfile:\n",
    "    completion = client.chat.completions.create(\n",
    "        # turbo (1106-preview) has 128k context window, about 300 pages of text\n",
    "        model=\"gpt-4-1106-preview\", # test with: gpt-3.5-turbo, run final: gpt-4-1106-preview\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \n",
    "                \"\"\"You are a writing a literature review about the use of tree-based algorithms \n",
    "                in modeling armed civil conflicts. I will provide you with multiple existing research \n",
    "                papers on the subject with the paper title, abstract, authors, and year of publication.\n",
    "                Please provide a detailed literature review based on these papers, focusing on the \n",
    "                methodologies used, the evolution of these techniques over time, and their effectiveness \n",
    "                in conflict analysis. Please include references in the text in an (author, year) format.\"\"\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Here is a list of the papers and the relevant information: {paper_abstracts}\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    gpt_summary = completion.choices[0].message.content\n",
    "    \n",
    "    txtfile.write(f\"{gpt_summary}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c-network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
