{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## paper ingestion\n",
    "given a link, I want to ingest the title, abstract, doi, and the doi of the other papers it cites (as well as the papers those papers cite). how many levels down i go in the graph will depend on how stringent my filtering function is.  \n",
    "\n",
    "currently using [this](https://api.semanticscholar.org/api-docs/graph#tag/Paper-Data/operation/get_graph_paper_bulk_search) api from semantic scholar and storing data locally as a json. in the futuer, will aim to use sqlite for persistance instead.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_doi = '10.1371/journal.pone.0286404'\n",
    "test_paper_id = 'c951ac9a54bba70c6e8337ab5815f3ac45434ec5'\n",
    "\n",
    "def create_url(id, is_doi=False):\n",
    "    endpoint = \"https://api.semanticscholar.org/graph/v1/paper/\"\n",
    "    fields = '?fields=title,abstract,url,year,authors,references'\n",
    "    if is_doi:\n",
    "        return endpoint + \"DOI:\" + id + fields\n",
    "    else: \n",
    "        return endpoint + id + fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# calling the semantic scholar api\n",
    "def api_call(api_endpoint):\n",
    "    response = requests.get(api_endpoint)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        print(api_endpoint)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# a lot of error handling, hasn't broken so far\n",
    "def try_api_call(api_endpoint):\n",
    "    try:\n",
    "        response = requests.get(api_endpoint)\n",
    "        if response.status_code == 429:\n",
    "            print(\"Rate limit reached. Waiting before retrying...\")\n",
    "            time.sleep(20)  # Sleep for a minute, or an appropriate back-off time for your use case\n",
    "            return api_call(api_endpoint)  # Retry the request\n",
    "        response.raise_for_status()  # Will raise an HTTPError for other bad status codes\n",
    "        return response.json()\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred: {http_err} - {api_endpoint}\")\n",
    "    except Exception as err:\n",
    "        print(f\"An error occurred: {err} - {api_endpoint}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# pretty print json object\n",
    "def pprint(data):\n",
    "    print(json.dumps(data, indent=4, sort_keys=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords\n",
    "ml_keywords=[\n",
    "    'machine learning', \n",
    "    'regression', \n",
    "    'neural network', \n",
    "    'model',\n",
    "    'projecting',\n",
    "    'forecast',\n",
    "    'predict',\n",
    "    'modeling',\n",
    "    'classification', \n",
    "    'clustering', \n",
    "    'support vector machine', \n",
    "    'decision tree', \n",
    "    'random forest', \n",
    "    'learning', \n",
    "    'gradient boosting', \n",
    "    'data mining', \n",
    "    'natural language processing', \n",
    "    'computer vision', \n",
    "    'algorithm', \n",
    "    'optimization', \n",
    "]\n",
    "conflict_keywords=[\n",
    "    'armed', \n",
    "    'civil',\n",
    "    'war', \n",
    "    'conflict',\n",
    "    'insurgency', \n",
    "    'terrorism', \n",
    "    'extremism', \n",
    "    'revolution', \n",
    "    'violence', \n",
    "    'warfare', \n",
    "    'battle', \n",
    "    'combat', \n",
    "    'militia', \n",
    "    'security', \n",
    "    'peacekeeping', \n",
    "    'genocide', \n",
    "    'massacre', \n",
    "    'ceasefire', \n",
    "    'rebellion', \n",
    "    'humanitarian', \n",
    "    'occupation', \n",
    "]\n",
    "all_keywords = ml_keywords + conflict_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_check(string):\n",
    "    string = string.lower()\n",
    "    return any(keyword in string for keyword in all_keywords)\n",
    "\n",
    "## used to create v0 of the graph\n",
    "## generally checks for machine learning + conflicts related keywords (both must be present)\n",
    "def double_keyword_check(string):\n",
    "    string = string.lower()\n",
    "    match1 = any(keyword.lower() in string for keyword in ml_keywords)\n",
    "    match2 = any(keyword.lower() in string for keyword in conflict_keywords)\n",
    "    return match1 and match2\n",
    "\n",
    "def paper_is_relevant(json_blob):\n",
    "    title = json_blob['title']\n",
    "    if double_keyword_check(title):\n",
    "        return True\n",
    "    else:\n",
    "        abstract = json_blob['abstract']\n",
    "        return double_keyword_check(abstract)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"database\": will make this a sqlite later\n",
    "# key: paperId, value: [api call data object, how many times hit]\n",
    "papers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_refs(paper_refs):\n",
    "    # first pass at filtering out references that don't pass the general keyword check\n",
    "    filtered_references = [\n",
    "        ref for ref in paper_refs\n",
    "        if keyword_check(ref['title'])\n",
    "    ]\n",
    "    return filtered_references\n",
    "\n",
    "# pprint(filter_refs(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing all the helpers thus far\n",
    "    \n",
    "def add_to_dict(res):\n",
    "    if res:\n",
    "        # there was a response\n",
    "        id = res['paperId']\n",
    "        if id in papers:\n",
    "            print('paper already in database')\n",
    "        else:\n",
    "            refs = filter_refs(res.pop('references', None))\n",
    "            papers[id] = [res, refs, 1]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_a_node(key):\n",
    "    value = papers[key]\n",
    "    # iterate through the refs\n",
    "    for ref in value[1]:\n",
    "        ref_id = ref['paperId']\n",
    "        if ref_id in papers:\n",
    "            # if the ref is already in the database, increment the hit count\n",
    "            papers[ref_id][2] += 1\n",
    "        else:  \n",
    "            # if the ref is not in the database, add it\n",
    "            url = create_url(ref_id)\n",
    "            res = api_call(url)\n",
    "            if res['abstract'] and double_keyword_check(res['abstract']):\n",
    "                add_to_dict(res)\n",
    "    # touched again\n",
    "    papers[key][2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c951ac9a54bba70c6e8337ab5815f3ac45434ec5': [{'paperId': 'c951ac9a54bba70c6e8337ab5815f3ac45434ec5', 'url': 'https://www.semanticscholar.org/paper/c951ac9a54bba70c6e8337ab5815f3ac45434ec5', 'title': 'Modeling analysis of armed conflict risk in sub-Saharan Africa, 2000–2019', 'abstract': 'Sub-Saharan Africa has suffered frequent outbreaks of armed conflict since the end of the Cold War. Although several efforts have been made to understand the underlying causes of armed conflict and establish an early warning mechanism, there is still a lack of a comprehensive assessment approach to model the incidence risk of armed conflict well. Based on a large database of armed conflict events and related spatial datasets covering the period 2000–2019, this study uses a boosted regression tree (BRT) approach to model the spatiotemporal distribution of armed conflict risk in sub-Saharan Africa. Evaluation of accuracy indicates that the simulated models obtain high performance with an area under the receiver operator characteristic curve (ROC-AUC) mean value of 0.937 and an area under the precision recall curves (PR-AUC) mean value of 0.891. The result of the relative contribution indicates that the background context factors (i.e., social welfare and the political system) are the main driving factors of armed conflict risk, with a mean relative contribution of 92.599%. By comparison, the climate change-related variables have relatively little effect on armed conflict risk, accounting for only 7.401% of the total. These results provide novel insight into modelling the incidence risk of armed conflict, which may help implement interventions to prevent and minimize the harm of armed conflict.', 'year': 2023, 'authors': [{'authorId': '2111366015', 'name': 'Xiaolan Xie'}, {'authorId': '2004912912', 'name': 'Dong Jiang'}, {'authorId': '145381688', 'name': 'Mengmeng Hao'}, {'authorId': '11258201', 'name': 'Fangyu Ding'}]}, [{'paperId': '7272b4fa037893b8d54cedd05903360528999557', 'title': 'Varying climatic-social-geographical patterns shape the conflict risk at regional and global scales'}, {'paperId': '5e2092e569a49b8404e4646eb7bfc8df51bc2fba', 'title': 'Lessons from an escalation prediction competition'}, {'paperId': '1ee89d8c4546a34238d715c073d248617d0f67ff', 'title': 'Quantifying the influence of climate variability on armed conflict in Africa, 2000–2015'}, {'paperId': '5a788a70a6b6cb35c6eaf3f335b4476c48d00b69', 'title': 'Modelling armed conflict risk under climate change with machine learning and time-series data'}, {'paperId': '01028e69dfd57d2738dcb39c057bbf952dbcb0af', 'title': 'Projecting armed conflict risk in Africa towards 2050 along the SSP-RCP scenarios: a machine learning approach'}, {'paperId': 'b8974a3094f93e59507c3b775822f3e819ead4db', 'title': 'ViEWS2020: Revising and evaluating the ViEWS political Violence Early-Warning System'}, {'paperId': '43b20758693fbd4df13f4f089d2000f3c837c7b1', 'title': 'Spatiotemporal patterns and spatial risk factors for visceral leishmaniasis from 2007 to 2017 in Western and Central China: A modelling analysis.'}, {'paperId': 'df55a75026085154d0a7cbdf794999939d372b3c', 'title': 'Temperature anomalies affect violent conflicts in African and Middle Eastern warm regions'}, {'paperId': '1e52a479cad4fedd32384aa346233203f9d19bbf', 'title': 'Climate has contrasting direct and indirect effects on armed conflicts'}, {'paperId': 'ef7a4b6f19a92290733151ecb789c9617ad7a9cf', 'title': 'Directions for Research on Climate and Conflict'}, {'paperId': 'ec64ff7c43d6742b3d372b13ddfc2db4f0733f5b', 'title': 'COVID-19 and armed conflict'}, {'paperId': '181f0578d940b6a6bb5c8613e149396709c3d4d1', 'title': 'Multi-method evidence for when and how climate-related disasters contribute to armed conflict risk'}, {'paperId': '3c71eef551cc09ca38f2578c76d315592273ab67', 'title': 'Local warming and violent armed conflict in Africa'}, {'paperId': '9a7f9d5697cb2534278676ff533fecb7b710731c', 'title': 'Risk factors and predicted distribution of visceral leishmaniasis in the Xinjiang Uygur Autonomous Region, China, 2005–2015'}, {'paperId': '49297cc1a5ecca63c34ca6c56699e3c6e6671f9e', 'title': 'Climate as a risk factor for armed conflict'}, {'paperId': 'e3239a1afb502fe194c5fda4675662772a829a1d', 'title': 'ViEWS: A political violence early-warning system'}, {'paperId': 'd80654d515d7f42f20f897893c809e782ce366a1', 'title': 'Climate War in the Middle East? Drought, the Syrian Civil War and the State of Climate-Conflict Research'}, {'paperId': 'c1258a812be1ee84be251f6455e38b1bf0169b96', 'title': 'The study of violence and social unrest in Africa: A comparative analysis of three conflict event datasets'}, {'paperId': 'e81e32f375691820ec2be837d4aed4f54d3eb11a', 'title': 'Environmental impacts and causes of conflict in the Horn of Africa: A review'}, {'paperId': '2e128cd02947725de76622dc04435b217fe4d56d', 'title': 'Predicting Conflict'}, {'paperId': 'aeac3f12ec7b2a490f1f67dcb6c13bc58faaed83', 'title': 'The shape of things to come? Expanding the inequality and grievance model for civil war forecasts with event data'}, {'paperId': '16ce39f8fd5e2036a6a347a667b543e4eef598bb', 'title': 'Climate Change and Collective Violence'}, {'paperId': '2a31dd2f126cd187cc5eb8dbbcd97ad42974ffc3', 'title': 'Civil conflict sensitivity to growing-season drought'}, {'paperId': '67d0efb80486ef0e1fd156f9c12329e15a272f20', 'title': 'An empirical comparison of classification algorithms for mortgage default prediction: evidence from a distressed mortgage market'}, {'paperId': '26acad24d7bbaea5abfe66092b11bca450d8b8ac', 'title': 'Square Pegs in Round Holes: Inequalities, Grievances, and Civil War'}, {'paperId': '7ee54020f8b279d0a82afe22b466db95c498be90', 'title': 'Quantifying the Influence of Climate on Human Conflict'}, {'paperId': '792e75d052a6fb31947b0161ded7c99c8f26a634', 'title': 'Predicting Armed Conflict, 2010–2050'}, {'paperId': '52c2bed21c279b3d31806891756c61790b2399ad', 'title': 'Climate variability and conflict risk in East Africa, 1990–2009'}, {'paperId': '3420b2e619566d5501ee705eeb217518aad1cbd9', 'title': 'Greed and grievance in civil war'}, {'paperId': '5c0155a58d7d2cdc502731769c018fda7b478c2f', 'title': 'Climate Change and Violent Conflict'}, {'paperId': '90cc83858b72542db45ed7664301c2b704bb6f5a', 'title': 'Introducing ACLED: An Armed Conflict Location and Event Dataset'}, {'paperId': 'c545ab4283787fe43cb0cf29de6b46e6bf511957', 'title': 'Political Marginalization, Climate Change, and Conflict in African Sahel States'}, {'paperId': '5642a582b9a9a238e0211ca85e796e9238cd6057', 'title': 'A Global Model for Forecasting Political Instability'}, {'paperId': '5254405a0d1000b57f32a2f6642d105e0b196caf', 'title': 'Warming increases the risk of civil war in Africa'}, {'paperId': '6ba9afd9241a5d04e2ce890f0a6f082d167968b8', 'title': 'A working guide to boosted regression trees.'}, {'paperId': '9f1037a0b5d2a47db49b34010a22b4888386b3f7', 'title': 'POLITICAL LIBERALIZATION OR ARMED CONFLICTS? POLITICAL CHANGES IN POST–COLD WAR AFRICA'}, {'paperId': '2435a02d3afb16ba00ebfa9c8f7df10b52cce80c', 'title': 'Sensitivity Analysis of Empirical Results on Civil War Onset'}, {'paperId': '0bdac412114ce931188d79922d0771a9bb5ba454', 'title': 'People vs. Malthus: Population Pressure, Environmental Degradation, and Armed Conflict Revisited'}, {'paperId': '0824070939b0db6741f032fb0cba54eb01b33ce7', 'title': 'Accounting for scale: Measuring geography in quantitative studies of civil war'}, {'paperId': 'f46c2b6b703c30f2c3684f18a205ae5c0497712e', 'title': 'Modeling the Size of Wars: From Billiard Balls to Sandpiles'}, {'paperId': '4ae60a3b82472ffa0011e086f2fa93828ddefb9a', 'title': 'Ethnicity, Insurgency, and Civil War'}, {'paperId': 'd4e1014f74c7f146be645860e66c80b9a35bf413', 'title': 'On the Duration of Civil War'}, {'paperId': '55d1396f6a53db42856cd110ba569e43316dae32', 'title': 'Modeling Social and Geopolitical Disasters as Extreme Events: A Case Study Considering the Complex Dynamics of International Armed Conflicts'}, {'paperId': '62c37991c1df1600fb4291467b9146154b65f4ff', 'title': 'Revisiting democratic civil peace: Electoral regimes and civil conflict'}, {'paperId': 'dff2ecc7375d14d9ced993e1bbe7f7deead9bc78', 'title': 'Political liberalization or armed conflicts? : Political changes in post-cold war Africa'}], 1]}\n"
     ]
    }
   ],
   "source": [
    "papers = {}\n",
    "\n",
    "# add the first node\n",
    "url = create_url(test_paper_id, False)\n",
    "res = api_call(url)\n",
    "add_to_dict(res)\n",
    "\n",
    "# print(papers)\n",
    "print(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary saved to papers.json\n"
     ]
    }
   ],
   "source": [
    "# no need to run\n",
    "from_a_node(test_paper_id)\n",
    "\n",
    "# Define the filename where you want to store the data\n",
    "filename = 'papers.json'\n",
    "\n",
    "# Write the dictionary to a file as JSON\n",
    "with open(filename, 'w') as file:\n",
    "    json.dump(papers, file, indent=4)\n",
    "\n",
    "print(f\"Dictionary saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_graph_to_file(graph_data, file_name):\n",
    "    with open(file_name, 'w') as file:\n",
    "        json.dump(graph_data, file, indent=4, default=str)  # Using default=str to handle non-serializable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## defaults to double keyword check (ML + conflicts) as filtering\n",
    "def generate_reference_network(start_paper_id, max_depth=2, filter_func=double_keyword_check, res_name='graph.json'):\n",
    "    graph = {}  # Initialize an empty graph, key: paper_id, value: paper_blob, list of references\n",
    "    start_blob = try_api_call(create_url(start_paper_id))\n",
    "    queue = [(start_paper_id, start_blob, 0)]  # Queue of (paper_id, current_depth)\n",
    "    visited = set()  # Set of visited paper IDs to avoid duplicates\n",
    "    save_interval = 1\n",
    "    processed_papers = 0  \n",
    "\n",
    "    while queue:\n",
    "        current_paper_id, paper_info, current_depth = queue.pop(0)\n",
    "        if current_paper_id not in visited and current_depth <= max_depth:\n",
    "            print(f\"Processing paper {current_paper_id} at depth {current_depth}\")\n",
    "            visited.add(current_paper_id)\n",
    "    \n",
    "            # Retrieve references and check if the paper meets the criteria\n",
    "            references = filter_refs(paper_info.pop('references', None))\n",
    "            print(\"------- the num of references are: \", len(references))\n",
    "            relevant_refs = []\n",
    "            for ref in references:\n",
    "                ref_id = ref['paperId']\n",
    "                if ref_id:\n",
    "                    url = create_url(ref_id)\n",
    "                    res = try_api_call(url)\n",
    "                    if res and res['abstract'] and filter_func(res['abstract']):\n",
    "                        relevant_refs.append(ref_id) \n",
    "                        queue.append((ref_id, res, current_depth + 1))\n",
    "            \n",
    "            graph[current_paper_id] = (paper_info, relevant_refs)\n",
    "            print(\"------- the rel references are: \", relevant_refs)\n",
    "\n",
    "            processed_papers += 1\n",
    "            \n",
    "            # Save the graph every three papers processed\n",
    "            if processed_papers % save_interval == 0:\n",
    "                save_graph_to_file(graph, res_name)\n",
    "                print(f\"Saved backup of graph at {processed_papers} papers.\")\n",
    "                \n",
    "    return graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## took 23 min 40 sec to get to 129 papers\n",
    "## rate is about 5 papers per minute\n",
    "\n",
    "# This will return a graph dictionary with each paper ID as keys and \n",
    "# the tuple (paper_info, lists of relevant references) as values.\n",
    "reference_network = generate_reference_network(test_paper_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Network\n",
    "Trying this exclusively for papers about RF as a conflict modeling tactic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RANDOM FOREST PAPERS\n",
    "# first node: \n",
    "# 10.1371/journal.pone.0286404\n",
    "\n",
    "rf_keywords = [\n",
    "    'forest',\n",
    "    'tree',\n",
    "    'random',\n",
    "    'decision tree',\n",
    "    'regression trees',\n",
    "    'boost',\n",
    "    'gradient',\n",
    "    'bagging',\n",
    "    'boosting',\n",
    "    'lightgbm',\n",
    "    'cart',\n",
    "    'adaboost',\n",
    "]\n",
    "\n",
    "## generally checks for keywords relating to random forest classification\n",
    "def filter_trees(string):\n",
    "    string = string.lower()\n",
    "    match1 = any(keyword.lower() in string for keyword in rf_keywords)\n",
    "    # for speed\n",
    "    if not match1:\n",
    "        return False\n",
    "    match2 = any(keyword.lower() in string for keyword in conflict_keywords)\n",
    "    return match1 and match2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## running the random forest tree generation \n",
    "# title: Comparing Random Forest with Logistic Regression for Predicting Class-Imbalanced Civil War Onset Data\n",
    "# published: 2016\n",
    "\n",
    "rf_doi = '10.1093/pan/mpv024'\n",
    "# res = try_api_call(create_url(rf_doi, True))\n",
    "\n",
    "rf_paper_id = '4b6555beef240120bacb699c7d2f7c8e806b5747'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing paper 4b6555beef240120bacb699c7d2f7c8e806b5747 at depth 0\n",
      "------- the num of references are:  47\n",
      "------- the rel references are:  ['a4d4053fa12ac75164fe2df0b20a4d3883c292c3', 'da0a744bd257cc50a8778b4452b253bbe3c0b654', '3a8743b858ed557e3c722095ad4d4158e271e0bd', '17c7d2aada72fe59c8d282235b26089d526e44ee']\n",
      "Saved backup of graph at 1 papers.\n",
      "Processing paper a4d4053fa12ac75164fe2df0b20a4d3883c292c3 at depth 1\n",
      "------- the num of references are:  27\n",
      "------- the rel references are:  ['18c332b0bad296f8722677d2d63092bf02e0c210', '25badc676197a70aaf9911865eb03469e402ba57']\n",
      "Saved backup of graph at 2 papers.\n",
      "Processing paper da0a744bd257cc50a8778b4452b253bbe3c0b654 at depth 1\n",
      "------- the num of references are:  12\n",
      "------- the rel references are:  ['2d1e0a5d5309354d4948fa88b01232e59eee94dc']\n",
      "Saved backup of graph at 3 papers.\n",
      "Processing paper 3a8743b858ed557e3c722095ad4d4158e271e0bd at depth 1\n",
      "------- the num of references are:  48\n",
      "------- the rel references are:  ['34122df837465c1f2025fabc3209964e7a3a205b', '807c1f19047f96083e13614f7ce20f2ac98c239a', '70c87b478d421a54e2a712861fd23e2e45265062']\n",
      "Saved backup of graph at 4 papers.\n",
      "Processing paper 17c7d2aada72fe59c8d282235b26089d526e44ee at depth 1\n",
      "------- the num of references are:  7\n",
      "------- the rel references are:  []\n",
      "Saved backup of graph at 5 papers.\n",
      "Processing paper 18c332b0bad296f8722677d2d63092bf02e0c210 at depth 2\n",
      "------- the num of references are:  27\n",
      "------- the rel references are:  ['a4d4053fa12ac75164fe2df0b20a4d3883c292c3', '873ee91bd87b4ec296db58618c891a39608e7fce', '4b6555beef240120bacb699c7d2f7c8e806b5747']\n",
      "Saved backup of graph at 6 papers.\n",
      "Processing paper 25badc676197a70aaf9911865eb03469e402ba57 at depth 2\n",
      "------- the num of references are:  535\n",
      "------- the rel references are:  ['03230c3c83dbb013c3e610702c6f650307f0ce5c', 'b71ac1e9fb49420d13e084ac67254a0bbd40f83f', 'e2b7f37cd97a7907b1b8a41138721ed06a0b76cd', 'ed3a2b1d571a8188f41341f9b5c675a7682792b0', '878783964ab23c97052ea82685368099d85c500d', 'f4ba954b0412773d047dc41231c733de0c1f4926', '3fc32c3ebbfa9de3168ae1c175bda839c9b44c21', '2d1e0a5d5309354d4948fa88b01232e59eee94dc', 'e0999dc17b35c0d893974f03d98293f71f27698b', 'd9c8b4f4a14b1568956f2a618c86728c6ce67390', '3d3c82d8989b0053da3fc7b0598cb72457442fd1', 'a6b80923dd30f920234a1ac965bea768062882f8', '83644e8e95e1a2034b32d363bc6865bc2e23f8c5', 'a5b40921ae03cc6fa34f532173a23c321c9ad3f7']\n",
      "Saved backup of graph at 7 papers.\n",
      "Processing paper 2d1e0a5d5309354d4948fa88b01232e59eee94dc at depth 2\n",
      "------- the num of references are:  11\n",
      "------- the rel references are:  []\n",
      "Saved backup of graph at 8 papers.\n",
      "Processing paper 34122df837465c1f2025fabc3209964e7a3a205b at depth 2\n",
      "------- the num of references are:  20\n",
      "------- the rel references are:  []\n",
      "Saved backup of graph at 9 papers.\n",
      "Processing paper 807c1f19047f96083e13614f7ce20f2ac98c239a at depth 2\n",
      "------- the num of references are:  0\n",
      "------- the rel references are:  []\n",
      "Saved backup of graph at 10 papers.\n",
      "Processing paper 70c87b478d421a54e2a712861fd23e2e45265062 at depth 2\n",
      "------- the num of references are:  7\n",
      "------- the rel references are:  ['2b461250c014b460e7c97b6138a3ee811f198f43']\n",
      "Saved backup of graph at 11 papers.\n",
      "Processing paper 873ee91bd87b4ec296db58618c891a39608e7fce at depth 3\n",
      "------- the num of references are:  39\n",
      "------- the rel references are:  ['2fcef1a302a3b3bda96bc3574ac1f7dc79c2ab48']\n",
      "Saved backup of graph at 12 papers.\n",
      "Processing paper 03230c3c83dbb013c3e610702c6f650307f0ce5c at depth 3\n",
      "------- the num of references are:  13\n",
      "------- the rel references are:  ['4af9104d10a244a93ff08773d14dc3a3f2491329']\n",
      "Saved backup of graph at 13 papers.\n",
      "Processing paper b71ac1e9fb49420d13e084ac67254a0bbd40f83f at depth 3\n",
      "------- the num of references are:  14\n",
      "------- the rel references are:  []\n",
      "Saved backup of graph at 14 papers.\n",
      "Processing paper e2b7f37cd97a7907b1b8a41138721ed06a0b76cd at depth 3\n",
      "------- the num of references are:  27\n",
      "------- the rel references are:  []\n",
      "Saved backup of graph at 15 papers.\n",
      "Processing paper ed3a2b1d571a8188f41341f9b5c675a7682792b0 at depth 3\n",
      "------- the num of references are:  60\n",
      "------- the rel references are:  ['f11261bd43487fe8f8083ff618d23f271ae38803', 'be454e68b34b9a5ce784e64d420b24c4e454ff9b']\n",
      "Saved backup of graph at 16 papers.\n",
      "Processing paper 878783964ab23c97052ea82685368099d85c500d at depth 3\n",
      "------- the num of references are:  12\n",
      "------- the rel references are:  ['f4ba954b0412773d047dc41231c733de0c1f4926', '8f3899c8726d8316dabb2d5152be73a2a572b371']\n",
      "Saved backup of graph at 17 papers.\n",
      "Processing paper f4ba954b0412773d047dc41231c733de0c1f4926 at depth 3\n",
      "------- the num of references are:  18\n",
      "------- the rel references are:  []\n",
      "Saved backup of graph at 18 papers.\n",
      "Processing paper 3fc32c3ebbfa9de3168ae1c175bda839c9b44c21 at depth 3\n",
      "------- the num of references are:  19\n",
      "------- the rel references are:  ['eb4d687f1a3a2aac529ceac4a67f2290cc380317']\n",
      "Saved backup of graph at 19 papers.\n",
      "Processing paper e0999dc17b35c0d893974f03d98293f71f27698b at depth 3\n",
      "------- the num of references are:  31\n",
      "------- the rel references are:  []\n",
      "Saved backup of graph at 20 papers.\n",
      "Processing paper d9c8b4f4a14b1568956f2a618c86728c6ce67390 at depth 3\n",
      "------- the num of references are:  17\n",
      "------- the rel references are:  []\n",
      "Saved backup of graph at 21 papers.\n",
      "Processing paper 3d3c82d8989b0053da3fc7b0598cb72457442fd1 at depth 3\n",
      "------- the num of references are:  1\n",
      "------- the rel references are:  []\n",
      "Saved backup of graph at 22 papers.\n",
      "Processing paper a6b80923dd30f920234a1ac965bea768062882f8 at depth 3\n",
      "------- the num of references are:  0\n",
      "------- the rel references are:  []\n",
      "Saved backup of graph at 23 papers.\n",
      "Processing paper 83644e8e95e1a2034b32d363bc6865bc2e23f8c5 at depth 3\n",
      "------- the num of references are:  3\n",
      "------- the rel references are:  []\n",
      "Saved backup of graph at 24 papers.\n",
      "Processing paper a5b40921ae03cc6fa34f532173a23c321c9ad3f7 at depth 3\n",
      "------- the num of references are:  91\n",
      "------- the rel references are:  ['2d1e0a5d5309354d4948fa88b01232e59eee94dc']\n",
      "Saved backup of graph at 25 papers.\n",
      "Processing paper 2b461250c014b460e7c97b6138a3ee811f198f43 at depth 3\n",
      "------- the num of references are:  6\n",
      "------- the rel references are:  []\n",
      "Saved backup of graph at 26 papers.\n"
     ]
    }
   ],
   "source": [
    "## Actual generation\n",
    "rf_network = generate_reference_network(rf_paper_id, max_depth=3, filter_func=filter_trees, res_name='rf_graph.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try_api_call(create_url(\"10.1007/978-3-319-55708-3_19\", True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c-network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
