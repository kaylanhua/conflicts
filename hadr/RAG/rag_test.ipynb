{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with GDELT data\n",
    "\n",
    "## sources\n",
    "- GDELT data [here](https://blog.gdeltproject.org/gdelt-doc-2-0-api-debuts/)\n",
    "- llama index [github](https://github.com/run-llama/llama_index)\n",
    "- following this [tutorial from AV](https://www.analyticsvidhya.com/blog/2023/10/rag-pipeline-with-the-llama-index/)\n",
    "  - and [this one from medium](https://medium.com/@sandyludosky/rag-and-internet-browsing-eng-56ac9bb073a9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.vectorstores import Chroma\n",
    "# from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "import os\n",
    "import json\n",
    "\n",
    "from llama_index.core import ServiceContext, PromptHelper, VectorStoreIndex, SimpleDirectoryReader, set_global_service_context \n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.text_splitter import TokenTextSplitter\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "\n",
    "from tqdm import tqdm\n",
    "from trafilatura.sitemaps import sitemap_search\n",
    "from trafilatura import extract_metadata\n",
    "\n",
    "## API KEYS\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "openai.organization = \"org-raWgaVqCbuR9YlP1CIjclYHk\" # Harvard\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(True if openai.api_key else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sudan\n",
      "[\n",
      "    \"https://www.yenisafak.com/en/news/uae-contributes-25m-to-un-for-humanitarian-efforts-in-sudan-south-sudan-3686356\",\n",
      "    \"https://news.webindia123.com/news/Articles/World/20240624/4208555.html\",\n",
      "    \"https://gulfnews.com/uae/uae-contributes-25-million-to-un-for-humanitarian-efforts-in-sudan-1.103250476\",\n",
      "    \"https://allafrica.com/stories/202406230024.html\",\n",
      "    \"https://www.radiotamazuj.org/en/news/article/muslim-leader-calls-on-kiir-to-mediate-peace-in-sudan\",\n",
      "    \"https://www.standardmedia.co.ke/opinion/article/2001496412/south-sudan-can-unlock-its-potential-with-the-help-of-investors\",\n",
      "    \"https://www.standardmedia.co.ke/business/article/2001496412/south-sudan-can-unlock-its-potential-with-the-help-of-investors\",\n",
      "    \"https://www.marketscreener.com/news/latest/Sudan-oil-pipeline-resumption-imminent-says-South-Sudan-official-46842113/\",\n",
      "    \"https://reliefweb.int/report/sudan/sudan-over-1500-children-subjected-extreme-violence-conflict-breaks-records-crimes-against-children\",\n",
      "    \"https://dunyanews.tv/en/World/817093-Sudan-could-soon-have-10-million-internally-displaced-people,-UN-agency-\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "## GRABBING THE DATA FROM GDELT \n",
    "import requests\n",
    "import json\n",
    "\n",
    "# def get_gdelt_data(query):\n",
    "#     url = \"https://api.gdeltproject.org/api/v2/doc/doc?query=(%22islamic%20state%22%20OR%20isis%20OR%20somalia)&mode=artlist&maxrecords=100&timespan=1week&format=JSON\"\n",
    "#     try:\n",
    "#         response = requests.get(url)\n",
    "#         response.raise_for_status()\n",
    "#         return response.json()\n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         print(f\"Request failed: {e}\")\n",
    "#     except json.JSONDecodeError as e:\n",
    "#         print(f\"JSON decode error: {e.msg}\")\n",
    "#         raise json.JSONDecodeError(e.msg, e.doc, e.pos)\n",
    "\n",
    "def get_gdelt_data(query, start_date, end_date):\n",
    "    base_url = \"https://api.gdeltproject.org/api/v2/doc/doc\"\n",
    "    print(query)\n",
    "    lang_query = f\"{query} sourcelang:english\"\n",
    "    params = {\n",
    "        \"query\": lang_query,\n",
    "        \"mode\": \"artlist\",\n",
    "        \"format\": \"json\",\n",
    "        \"startdatetime\": start_date.strftime(\"%Y%m%d%H%M%S\"),\n",
    "        \"enddatetime\": end_date.strftime(\"%Y%m%d%H%M%S\"),\n",
    "        \"maxrecords\": 10,\n",
    "    }\n",
    "    response = requests.get(base_url, params=params).json()\n",
    "    urls = [article[\"url\"] for article in response.get(\"articles\", [])]\n",
    "    return urls\n",
    "\n",
    "# TODO make this legit responsive \n",
    "query = \"sudan\"\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=30) \n",
    "gdelt_data = get_gdelt_data(query, start_date, end_date)\n",
    "print(json.dumps(gdelt_data, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## RETRIEVING THE URLS N READING\n",
    "# urls = [article[\"url\"] for article in gdelt_data.get(\"articles\", [])]\n",
    "# print(urls)\n",
    "# print(len(urls)) # usually 100\n",
    "\n",
    "# test = urls[:20]\n",
    "\n",
    "urls = gdelt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(list_of_websites: list) :\n",
    "    \"\"\"\n",
    "    scrapes the data from the list of websites\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for url in tqdm(list_of_websites, desc=\"urls\"):\n",
    "        try:\n",
    "            # Send HTTP request to the URL\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()  # Check for successful response\n",
    "            # Parse HTML content\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            metadata = extract_metadata(response.content)\n",
    "            title = soup.title.string\n",
    "            description = metadata.description\n",
    "            # Extract text from each paragraph\n",
    "            paragraphs = [p.get_text(strip=True) for p in soup.find_all(\"p\")]\n",
    "            content = \"\\n\".join(paragraphs)\n",
    "            d = {\n",
    "                \"url\": url,\n",
    "                \"title\": title,\n",
    "                \"body\": content,\n",
    "                \"description\": description,\n",
    "            }\n",
    "            data.append(d)\n",
    "        except requests.exceptions.HTTPError as errh:\n",
    "            print(f\"HTTP Error: {errh}\")\n",
    "        except requests.exceptions.ConnectionError as errc:\n",
    "            print(f\"Error Connecting: {errc}\")\n",
    "        except requests.exceptions.Timeout as errt:\n",
    "            print(f\"Timeout Error: {errt}\")\n",
    "        except requests.RequestException as err:\n",
    "            print(f\"Error during requests to {url}: {str(err)}\")\n",
    "    return data\n",
    "\n",
    "def scrape(list_of_websites: list) -> None:\n",
    "    data = create_dataset(list_of_websites)\n",
    "\n",
    "    current_time = datetime.now().strftime(\"%d%H%M%S\")\n",
    "    dataset_filename = f\"./data/dataset_{current_time}.txt\"\n",
    "\n",
    "    with open(dataset_filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        for paragraph in data:\n",
    "            file.write(\"\\n\" + paragraph[\"title\"] + \"\\n\")\n",
    "            file.write(paragraph[\"body\"]+\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "urls:  10%|█         | 1/10 [00:00<00:00,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error: 422 Client Error:  for url: https://www.yenisafak.com/en/news/uae-contributes-25m-to-un-for-humanitarian-efforts-in-sudan-south-sudan-3686356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "urls:  80%|████████  | 8/10 [00:08<00:02,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error: 403 Client Error: Forbidden. for url: https://www.marketscreener.com/news/latest/Sudan-oil-pipeline-resumption-imminent-says-South-Sudan-official-46842113/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "urls: 100%|██████████| 10/10 [00:10<00:00,  1.10s/it]\n"
     ]
    }
   ],
   "source": [
    "## CREATE DOCUMENT SET\n",
    "scrape(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 6513, which is longer than the specified 100\n",
      "Created a chunk of size 2249, which is longer than the specified 100\n",
      "Created a chunk of size 8380, which is longer than the specified 100\n",
      "Created a chunk of size 153, which is longer than the specified 100\n",
      "Created a chunk of size 1468, which is longer than the specified 100\n",
      "Created a chunk of size 18271, which is longer than the specified 100\n",
      "Created a chunk of size 18271, which is longer than the specified 100\n",
      "Created a chunk of size 5297, which is longer than the specified 100\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters.character import CharacterTextSplitter\n",
    "import os\n",
    "\n",
    "## FRAGMENTING DOCUMENTS\n",
    "def split_documents():\n",
    "    \"\"\"Load the most recent file from the data folder, split it into chunks, embed each chunk and load it into the vector store.\"\"\"\n",
    "    data_folder = \"./data\"\n",
    "    files = os.listdir(data_folder)\n",
    "    latest_file = max([os.path.join(data_folder, f) for f in files], key=os.path.getctime)\n",
    "    raw_documents = TextLoader(latest_file).load()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "    return text_splitter.split_documents(raw_documents)\n",
    "\n",
    "docs = split_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import (\n",
    "    CharacterTextSplitter,\n",
    ")\n",
    "from langchain.prompts.chat import (\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Muslim leader calls on Kiir to mediate peace in Sudan - Radio Tamazuj\\nRadio Tamazuj\\nIndependent News Crossing Borders\\nSheikh Abdalah Barac. (File photo)', metadata={'source': './data/dataset_24140820.txt'}), Document(page_content='Muslim leader calls on Kiir to mediate peace in Sudan - Radio Tamazuj\\nRadio Tamazuj\\nIndependent News Crossing Borders\\nSheikh Abdalah Barac. (File photo)', metadata={'source': './data/dataset_24140820.txt'}), Document(page_content='The Secretary-General of the Islamic Council of South Sudan has appealed to the South Sudanese President Salva Kiir to mediate to resolve the dispute between the warring parties in Sudan to bring peace and lasting stability.\\nSpeaking to Radio Tamzuj on Sunday in Juba, Sheikh Abdallah Barac, described the president as the right person to arbitrate the conflict in Sudan.\\n“I appeal to President Kiir to have an effective role in bringing about peace in the state of Sudan and to bring all parties to the conflict to negotiations,” he said.\\nAccording to Sheikh Barac, a conflict in neighboring Sudan will undoubtedly affect South Sudan because the two countries are bound together by many things.\\n“South Sudan is the most suitable as a mediator, is neutral and our president is knowledgeable and has the respect of all parties in Sudan,” he said.\\nThe Muslim leader welcomed the Sudanese refugees in South Sudan, saying that South Sudan has to return the favor to the Sudanese people who hosted South Sudanese who fled to their country after war erupted in December 2013. He said Sudan also played a big role in the realization of the 2018 revitalized peace agreement which brought peace to South Sudan.\\n“You (Sudanese) are at home and among your families in South Sudan and I am sure that they are not sitting there feeling alienated,” Sheikh Barac stated. “We rejoice together. We thank the government of South Sudan for the good reception given to Sudanese refugees.”', metadata={'source': './data/dataset_24140820.txt'}), Document(page_content='The Secretary-General of the Islamic Council of South Sudan has appealed to the South Sudanese President Salva Kiir to mediate to resolve the dispute between the warring parties in Sudan to bring peace and lasting stability.\\nSpeaking to Radio Tamzuj on Sunday in Juba, Sheikh Abdallah Barac, described the president as the right person to arbitrate the conflict in Sudan.\\n“I appeal to President Kiir to have an effective role in bringing about peace in the state of Sudan and to bring all parties to the conflict to negotiations,” he said.\\nAccording to Sheikh Barac, a conflict in neighboring Sudan will undoubtedly affect South Sudan because the two countries are bound together by many things.\\n“South Sudan is the most suitable as a mediator, is neutral and our president is knowledgeable and has the respect of all parties in Sudan,” he said.\\nThe Muslim leader welcomed the Sudanese refugees in South Sudan, saying that South Sudan has to return the favor to the Sudanese people who hosted South Sudanese who fled to their country after war erupted in December 2013. He said Sudan also played a big role in the realization of the 2018 revitalized peace agreement which brought peace to South Sudan.\\n“You (Sudanese) are at home and among your families in South Sudan and I am sure that they are not sitting there feeling alienated,” Sheikh Barac stated. “We rejoice together. We thank the government of South Sudan for the good reception given to Sudanese refugees.”', metadata={'source': './data/dataset_24140820.txt'})]\n"
     ]
    }
   ],
   "source": [
    "## VECTOR STORE \n",
    "def load_embeddings(documents):\n",
    "    \"\"\"Create a vector store from a set of documents.\"\"\"\n",
    "    db = Chroma.from_documents(documents, OpenAIEmbeddings())\n",
    "    # docs = db.similarity_search(user_query)\n",
    "    return db\n",
    "    # return db.as_retriever()\n",
    "\n",
    "vector_db = load_embeddings(docs)\n",
    "print(vector_db.similarity_search(\"islamic state\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c-network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
